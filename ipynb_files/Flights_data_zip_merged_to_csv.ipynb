{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VA479zKKBBur",
        "outputId": "fd08c575-7a7c-4e07-85ef-d0dea6b33544"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All CSV files have been merged and saved to output/merged_2024.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "\n",
        "dataset_folder = '/content/Dataset'  # this path consist all .zip files of particular year\n",
        "output_folder = 'output'    # path where merged file is stored\n",
        "output_file = 'merged_Jan_2024.csv'\n",
        "\n",
        "# Create the output folder if it doesn't exist\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "# list to store DataFrames\n",
        "df_list = []\n",
        "\n",
        "# Iterate over all .zip files in the dataset folder\n",
        "for filename in os.listdir(dataset_folder):\n",
        "    if filename.endswith('.zip'):\n",
        "        zip_path = os.path.join(dataset_folder, filename)\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            # Assuming each zip file contains one CSV file\n",
        "            for file in zip_ref.namelist():\n",
        "                if file.endswith('.csv'):\n",
        "                    # Read the CSV file directly from the zip file\n",
        "                    with zip_ref.open(file) as csv_file:\n",
        "                        df = pd.read_csv(csv_file)\n",
        "                        df_list.append(df)\n",
        "                    break  # Assuming only one CSV per zip file\n",
        "            else:\n",
        "                print(f\"No CSV file found in {filename}\")\n",
        "\n",
        "# Concatenate all DataFrames\n",
        "if df_list:\n",
        "    merged_df = pd.concat(df_list, ignore_index=True)\n",
        "\n",
        "    # Save the concatenated DataFrame to the output folder\n",
        "    output_path = os.path.join(output_folder, output_file)\n",
        "    merged_df.to_csv(output_path, index=False)\n",
        "\n",
        "    print(f\"All CSV files have been merged and saved to {output_path}\")\n",
        "else:\n",
        "    print(\"No CSV files were found to merge.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Processing:**\n",
        "\n",
        "The script iterates over each .zip file in the Dataset folder.\n",
        "\n",
        "It extracts the .csv file inside each zip without extracting the entire zip file to disk.\n",
        "\n",
        "Each CSV is read into a pandas DataFrame and appended to a list.\n",
        "\n",
        "All DataFrames in the list are concatenated into a single DataFrame.\n",
        "\n",
        "The merged DataFrame is saved as merged.csv in the output folder."
      ],
      "metadata": {
        "id": "Q8zH6qU_G3cx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6c7XbfefG9Xj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
