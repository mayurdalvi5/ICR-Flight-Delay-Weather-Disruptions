{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import csv\n",
        "import codecs\n",
        "import calendar\n",
        "from datetime import datetime, timedelta"
      ],
      "metadata": {
        "id": "L151OpnfUOT7"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch(station_ids, start_date, end_date):\n",
        "    \"\"\"Download data for the specified stations and date range, excluding rows where tmpf is 'M'.\"\"\"\n",
        "    localfn = f\"stations_{start_date.strftime('%Y%m%d')}_{end_date.strftime('%Y%m%d')}_filtered.csv\"\n",
        "    if os.path.isfile(localfn):\n",
        "        print(f\"- File Already Exist: {localfn}\")\n",
        "        return\n",
        "    print(f\"+ Downloading data for stations {', '.join(station_ids)} from {start_date} to {end_date}\")\n",
        "\n",
        "    # Construct the URI to download data\n",
        "    stations_str = \",\".join(station_ids)\n",
        "    uri = (\n",
        "        \"https://mesonet.agron.iastate.edu/cgi-bin/request/asos.py?\"\n",
        "        f\"station={stations_str}&\"\n",
        "        \"data=tmpf,dwpf,relh,drct,sknt,p01i,alti,mslp,vsby,gust,\"\n",
        "        \"skyc1,skyc2,skyc3,skyc4,skyl1,skyl2,skyl3,skyl4,wxcodes,\"\n",
        "        \"ice_accretion_1hr,ice_accretion_3hr,ice_accretion_6hr,\"\n",
        "        \"peak_wind_gust,peak_wind_drct,peak_wind_time,feel,metar,snowdepth&\"\n",
        "        f\"year1={start_date.year}&month1={start_date.month}&day1={start_date.day}&\"\n",
        "        f\"year2={end_date.year}&month2={end_date.month}&day2={end_date.day}&\"\n",
        "        \"tz=UTC&format=onlycomma&latlon=no&elev=no&missing=M&trace=T&direct=yes\"\n",
        "    )\n",
        "\n",
        "    # Fetch data from the API using streaming to avoid loading the entire response into memory\n",
        "    with requests.get(uri, stream=True, timeout=300) as res:\n",
        "        if res.status_code == 200:\n",
        "            # Prepare to decode the streamed content\n",
        "            decoded_stream = codecs.iterdecode(res.iter_lines(), 'utf-8')\n",
        "            reader = csv.reader(decoded_stream)\n",
        "            headers = next(reader)  # Extract headers\n",
        "\n",
        "            # Find the index of 'tmpf' in headers\n",
        "            try:\n",
        "                tmpf_index = headers.index('tmpf')\n",
        "            except ValueError:\n",
        "                print(\"Error: 'tmpf' column not found in headers.\")\n",
        "                return\n",
        "\n",
        "            # Open the output file\n",
        "            with open(localfn, \"w\", newline='', encoding=\"utf-8\") as fh:\n",
        "                writer = csv.writer(fh)\n",
        "                writer.writerow(headers)  # Write headers\n",
        "\n",
        "                row_count = 0\n",
        "                # Process each row as it comes in\n",
        "                for row in reader:\n",
        "                    if len(row) == len(headers):  # Ensure row has correct number of columns\n",
        "                        tmpf_value = row[tmpf_index]\n",
        "                        if tmpf_value != 'M':  # Exclude rows where tmpf is 'M'\n",
        "                            writer.writerow(row)\n",
        "                            row_count += 1\n",
        "\n",
        "            print(f\"+ Data saved to {localfn} with {row_count} rows (excluding rows where tmpf='M').\")\n",
        "        else:\n",
        "            print(f\"Failed to download data: {res.status_code}\")"
      ],
      "metadata": {
        "id": "HEKNIroxdOwp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"Main entry to fetch data.\"\"\"\n",
        "    # Define the station IDs\n",
        "    station_ids = ['ALB', 'BGM', 'BUF', 'ELM', 'HPN', 'IAG', 'ISP', 'ITH', 'JFK', 'LGA', 'PBG', 'ROC', 'SWF', 'SYR']\n",
        "\n",
        "    # Specify the year and month\n",
        "    year = 2024\n",
        "    month = 1  # For February\n",
        "\n",
        "    # Determine the start_date and end_date\n",
        "    start_date = datetime(year, month, 1)\n",
        "\n",
        "    # Get the first weekday and number of days in the month\n",
        "    first_weekday, num_days = calendar.monthrange(year, month)\n",
        "    # Alternatively, if we don't need first_weekday, we can do:\n",
        "    # num_days = calendar.monthrange(year, month)[1]\n",
        "\n",
        "    # Calculate end_date as the first day of the next month\n",
        "    end_date = start_date + timedelta(days=num_days)\n",
        "\n",
        "    # Fetch data for the stations\n",
        "    fetch(station_ids, start_date, end_date)\n"
      ],
      "metadata": {
        "id": "JsDta_Hwo_LU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "mkndJoz4sCn7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62c8376d-7d10-4df2-d1ed-61d5115abe38"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+ Downloading data for stations ALB, BGM, BUF, ELM, HPN, IAG, ISP, ITH, JFK, LGA, PBG, ROC, SWF, SYR from 2024-01-01 00:00:00 to 2024-02-01 00:00:00\n",
            "+ Data saved to stations_20240101_20240201_filtered.csv with 14844 rows (excluding rows where tmpf='M').\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Purpose:**\n",
        "\n",
        "The script downloads and processes weather data for specified stations and a given month and year.\n",
        "\n",
        "Data Filtering: It excludes any data rows where the temperature (tmpf) value is missing.\n",
        "\n",
        "Output: The cleaned data is saved to a CSV file named according to the date range.\n",
        "\n",
        "Customization: You can change the year, month, and station_ids to fetch data for different periods and stations.\n"
      ],
      "metadata": {
        "id": "qV4jt0GC1BxC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "35848Kz61Ikm"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}