{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preliminary SVM Testing on Flight Delays\n",
        "\n",
        "### By: Tristan Levy-Park"
      ],
      "metadata": {
        "id": "eHlYwR9cNy5F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Working with Unbalanced Data"
      ],
      "metadata": {
        "id": "KA0snT_EQ_fm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/Dataset/Illinois_10_years_data.csv')\n",
        "\n",
        "# Drop rows with missing values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "df = df[df['Month'] == 1]\n",
        "\n",
        "# Downsample the data to reduce size (e.g., sample 1% of the data)\n",
        "df = df.sample(frac=0.5, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Convert integer features to int32 for memory efficiency\n",
        "int_columns = ['Year', 'Quarter', 'Month', 'Day_of_Month', 'Day_of_Week', 'Scheduled_Departure_Time', 'Scheduled_Departure_Time_Minutes', 'Target']\n",
        "for col in int_columns:\n",
        "    df[col] = df[col].astype(np.int32)\n",
        "\n",
        "# Convert continuous numeric features to float32\n",
        "float_columns = ['Taxi_Out_Time_Minutes', 'Flight_Distance_Miles', 'Air_Temperature_Fahrenheit', 'Dew_Point_Temperature_Fahrenheit',\n",
        "                 'Relative_Humidity_Percent', 'Wind_Direction_Degrees', 'Wind_Speed_Knots', 'Hourly_Precipitation_Inches',\n",
        "                 'Pressure_Altimeter_Inches', 'Sea_Level_Pressure_Millibar', 'Visibility_Miles', 'Sky_Level_1_Altitude_Feet',\n",
        "                 'Apparent_Temperature_Fahrenheit']\n",
        "for col in float_columns:\n",
        "    df[col] = df[col].astype(np.float32)\n",
        "\n",
        "# Drop unnecessary columns\n",
        "df = df.drop(['Origin_State_Name', 'Departure_Datetime', 'Departure_Delay_Minutes'], axis=1)\n",
        "\n",
        "# Define categorical columns\n",
        "categorical_columns = ['Operating_Carrier_Code', 'Tail_Number', 'Origin_Airport_ID', 'Origin_Airport_Code', 'Destination_Airport_Code', 'Destination_State_Name', 'Sky_Cover_Level_1']\n",
        "\n",
        "# Separate high-cardinality and low-cardinality categorical columns\n",
        "high_cardinality_columns = ['Tail_Number', 'Origin_Airport_Code', 'Destination_Airport_Code']\n",
        "low_cardinality_columns = [col for col in categorical_columns if col not in high_cardinality_columns]\n",
        "\n",
        "# Apply label encoding to high-cardinality categorical features\n",
        "label_encoders = {}\n",
        "for col in high_cardinality_columns:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Apply one-hot encoding to low-cardinality categorical features\n",
        "df = pd.get_dummies(df, columns=low_cardinality_columns, drop_first=True)\n",
        "\n",
        "# Define the years for each dataset\n",
        "train_years = [2014, 2015, 2016, 2017, 2018, 2019]\n",
        "val_years = [2020, 2021, 2022]\n",
        "test_years = [2023, 2024]\n",
        "\n",
        "# Create train, validation, and test sets\n",
        "train_df = df[df['Year'].isin(train_years)].reset_index(drop=True)\n",
        "val_df = df[df['Year'].isin(val_years)].reset_index(drop=True)\n",
        "test_df = df[df['Year'].isin(test_years)].reset_index(drop=True)\n",
        "\n",
        "# Separate features and target variable\n",
        "X_train = train_df.drop('Target', axis=1)\n",
        "y_train = train_df['Target']\n",
        "X_val = val_df.drop('Target', axis=1)\n",
        "y_val = val_df['Target']\n",
        "X_test = test_df.drop('Target', axis=1)\n",
        "y_test = test_df['Target']\n",
        "\n",
        "# Standardize numeric features to improve SVM model performance\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train the LinearSVC model\n",
        "svm_model = LinearSVC(random_state=42)\n",
        "svm_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = svm_model.predict(X_test_scaled)\n",
        "y_pred_scores = svm_model.decision_function(X_test_scaled)  # Use decision_function for score-based metrics\n",
        "\n",
        "# Evaluate on validation set\n",
        "y_val_pred = svm_model.predict(X_val_scaled)\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
        "print(\"\\nClassification Report on Validation Set:\\n\", classification_report(y_val, y_val_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_val, y_val_pred))\n",
        "\n",
        "# Evaluate on test set\n",
        "y_test_pred = svm_model.predict(X_test_scaled)\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
        "print(\"\\nClassification Report on Test Set:\\n\", classification_report(y_test, y_test_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred))\n",
        "\n",
        "# Visualization Metrics\n",
        "# 1. Confusion Matrix Heatmap\n",
        "plt.figure(figsize=(6, 4))\n",
        "conf_matrix = confusion_matrix(y_val, y_val_pred)  # Store it in 'conf_matrix'\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['No Delay', 'Delay'], yticklabels=['No Delay', 'Delay'])\n",
        "plt.title(\"Confusion Matrix of Validation Set\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "conf_matrix = confusion_matrix(y_test, y_test_pred)  # Store it in 'conf_matrix'\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['No Delay', 'Delay'], yticklabels=['No Delay', 'Delay'])\n",
        "plt.title(\"Confusion Matrix of Test Set\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()\n",
        "\n",
        "# 2. ROC Curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_scores)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(fpr, tpr, color='blue', label='AUC = %0.2f' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# 3. Precision-Recall Curve\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_pred_scores)\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(recall, precision, color='purple')\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision-Recall Curve\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "m8pxVPEK9K5K",
        "outputId": "d8c58a06-9e2c-4fb4-9879-0f67930e1c05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "partially initialized module 'pandas' has no attribute '_pandas_parser_CAPI' (most likely due to a circular import)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-79b5d0bec8d9>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Import necessary libraries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Import necessary libraries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    136\u001b[0m )\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplotting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtseries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_print_versions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/api/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"\"\" public toolkit API \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m from pandas.api import (\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mindexers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0minterchange\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/api/typing/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# TODO: Can't import Styler without importing jinja2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# from pandas.io.formats.style import Styler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_json\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mJsonReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStataReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/json/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from pandas.io.json._json import (\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mread_json\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mto_json\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mujson_dumps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mujson_loads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mparse_table_schema\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m )\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreaders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mTYPE_CHECKING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from pandas.io.parsers.readers import (\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mTextFileReader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mTextParser\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mread_csv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mread_fwf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_libs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_libs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSTR_NA_VALUES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m from pandas.errors import (\n\u001b[1;32m     34\u001b[0m     \u001b[0mAbstractMethodError\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36minit pandas._libs.parsers\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'pandas' has no attribute '_pandas_parser_CAPI' (most likely due to a circular import)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results of Unbalanced Data"
      ],
      "metadata": {
        "id": "SEXj057YFmm3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**For the Validation Set:**\n",
        "\n",
        "* We get an accuracy of 86.3% which seems high, but it's misleading. This accuracy reflects that the model is heavily biased towards predicting the majority class (no delay), which dominates the dataset.\n",
        "\n",
        "* Class 0 (No Delay): The model has high precision (0.86) and recall (1.00), meaning it correctly identifies non-delayed flights.\n",
        "\n",
        "* Class 1 (Delay): Precision and recall are both 0, indicating that the model fails to identify any delays. This likely occurs because of class imbalance—there are far fewer delayed flights compared to non-delayed ones, so the model defaults to predicting \"No Delay\" for all instances.\n",
        "\n",
        "* The confusion matrix shows that all 946 delayed flights were classified as non-delayed, with no true positives for the delay class.\n",
        "\n",
        "**For the test set:**\n",
        "\n",
        "* We get an accuracy of 77%, which again seems reasonable at first glance but is similarly biased.\n",
        "\n",
        "* Class 0 (No Delay): Precision of 0.77 and perfect recall mean the model is very good at identifying non-delayed flights.\n",
        "\n",
        "* Class 1 (Delay): Like the validation set, the model fails to identify any delays, with a recall and precision of 0.\n",
        "\n",
        "* The matrix again shows that all delayed flights were misclassified as non-delayed."
      ],
      "metadata": {
        "id": "74XalPQTRMl_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have a heavily **Imbalanced** Dataset!"
      ],
      "metadata": {
        "id": "BpCt_BgHRPgt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thus, we need to Oversample the minority class (delays) or undersample the majority class (no delay). We can use the technique SMOTE (Synthetic Minority Over-sampling Technique) to generate synthetic samples for the minority class.\n"
      ],
      "metadata": {
        "id": "QWklSAl4RQIH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Balancing our Data, using LinearSVC() for computational improvement"
      ],
      "metadata": {
        "id": "GSk_plq2h9kc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Applying SMOTE() function to balance the dataset"
      ],
      "metadata": {
        "id": "KkolQkBVDD2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/Dataset/Illinois_10_years_data.csv')\n",
        "\n",
        "# Drop rows with missing values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Filter data to only include January\n",
        "df = df[df['Month'] == 1]\n",
        "\n",
        "# Downsample to 1% for performance (adjust as needed)\n",
        "df = df.sample(frac=0.5, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Convert integer features to int32 for memory efficiency\n",
        "int_columns = ['Year', 'Quarter', 'Month', 'Day_of_Month', 'Day_of_Week', 'Scheduled_Departure_Time', 'Scheduled_Departure_Time_Minutes', 'Target']\n",
        "for col in int_columns:\n",
        "    df[col] = df[col].astype(np.int32)\n",
        "\n",
        "# Convert continuous numeric features to float32\n",
        "float_columns = ['Taxi_Out_Time_Minutes', 'Flight_Distance_Miles', 'Air_Temperature_Fahrenheit', 'Dew_Point_Temperature_Fahrenheit',\n",
        "                 'Relative_Humidity_Percent', 'Wind_Direction_Degrees', 'Wind_Speed_Knots', 'Hourly_Precipitation_Inches',\n",
        "                 'Pressure_Altimeter_Inches', 'Sea_Level_Pressure_Millibar', 'Visibility_Miles', 'Sky_Level_1_Altitude_Feet',\n",
        "                 'Apparent_Temperature_Fahrenheit']\n",
        "for col in float_columns:\n",
        "    df[col] = df[col].astype(np.float32)\n",
        "\n",
        "# Drop unnecessary columns\n",
        "df = df.drop(['Origin_State_Name', 'Departure_Datetime', 'Departure_Delay_Minutes'], axis=1)\n",
        "\n",
        "# Define categorical columns\n",
        "categorical_columns = ['Operating_Carrier_Code', 'Tail_Number', 'Origin_Airport_ID', 'Origin_Airport_Code', 'Destination_Airport_Code', 'Destination_State_Name', 'Sky_Cover_Level_1']\n",
        "\n",
        "# Apply label encoding to high-cardinality categorical features\n",
        "label_encoders = {}\n",
        "for col in categorical_columns:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop('Target', axis=1)\n",
        "y = df['Target']\n",
        "\n",
        "# Split data into train, validation, and test sets by year\n",
        "train_years = [2014, 2015, 2016, 2017, 2018, 2019]\n",
        "val_years = [2020, 2021, 2022]\n",
        "test_years = [2023, 2024]\n",
        "\n",
        "train_df = df[df['Year'].isin(train_years)].reset_index(drop=True)\n",
        "val_df = df[df['Year'].isin(val_years)].reset_index(drop=True)\n",
        "test_df = df[df['Year'].isin(test_years)].reset_index(drop=True)\n",
        "\n",
        "# Separate features and target variable for train, validation, and test sets\n",
        "X_train = train_df.drop('Target', axis=1)\n",
        "y_train = train_df['Target']\n",
        "X_val = val_df.drop('Target', axis=1)\n",
        "y_val = val_df['Target']\n",
        "X_test = test_df.drop('Target', axis=1)\n",
        "y_test = test_df['Target']\n",
        "\n",
        "# Apply SMOTE only on training data\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train the LinearSVC model\n",
        "svm_model = LinearSVC(random_state=42)\n",
        "svm_model.fit(X_train_scaled, y_train_resampled)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = svm_model.predict(X_test_scaled)\n",
        "y_pred_scores = svm_model.decision_function(X_test_scaled)  # Use decision_function for score-based metrics\n",
        "\n",
        "# Evaluate on train set\n",
        "y_train_pred = svm_model.predict(X_train_scaled)\n",
        "print(\"Training Accuracy:\", accuracy_score(y_train_resampled, y_train_pred)) # Changed y_train to y_train_resampled\n",
        "print(\"\\nClassification Report on Training Set:\\n\", classification_report(y_train_resampled, y_train_pred)) # Changed y_train to y_train_resampled\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_train_resampled, y_train_pred)) # Changed y_train to y_train_resampled\n",
        "\n",
        "# Evaluate on validation set\n",
        "y_val_pred = svm_model.predict(X_val_scaled)\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
        "print(\"\\nClassification Report on Validation Set:\\n\", classification_report(y_val, y_val_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_val, y_val_pred))\n",
        "\n",
        "# Evaluate on test set\n",
        "y_test_pred = svm_model.predict(X_test_scaled)\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
        "print(\"\\nClassification Report on Test Set:\\n\", classification_report(y_test, y_test_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred))\n",
        "\n",
        "# Visualization Metrics\n",
        "# 1. Confusion Matrix Heatmap\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "conf_matrix = confusion_matrix(y_train_resampled, y_train_pred)  # Store it in 'conf_matrix'\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['No Delay', 'Delay'], yticklabels=['No Delay', 'Delay'])\n",
        "plt.title(\"Confusion Matrix of Training Set\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "conf_matrix = confusion_matrix(y_val, y_val_pred)  # Store it in 'conf_matrix'\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['No Delay', 'Delay'], yticklabels=['No Delay', 'Delay'])\n",
        "plt.title(\"Confusion Matrix of Validation Set\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "conf_matrix = confusion_matrix(y_test, y_test_pred)  # Store it in 'conf_matrix'\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['No Delay', 'Delay'], yticklabels=['No Delay', 'Delay'])\n",
        "plt.title(\"Confusion Matrix of Test Set\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()\n",
        "\n",
        "# 2. ROC Curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_scores)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(fpr, tpr, color='blue', label='AUC = %0.2f' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"Receiver Operating Characteristic (ROC) Curve on Test Set\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# 3. Precision-Recall Curve\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_pred_scores)\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(recall, precision, color='purple')\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision-Recall Curve on Test Set\")\n",
        "plt.show()\n",
        "\n",
        "# Get feature importance from LinearSVC\n",
        "feature_importance = np.abs(svm_model.coef_[0])  # Take absolute value to show strength regardless of direction\n",
        "\n",
        "# Create a DataFrame to pair feature names with their importance\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': feature_importance\n",
        "})\n",
        "\n",
        "# Sort features by importance\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Display feature importance\n",
        "print(\"Feature Importance:\\n\", feature_importance_df)\n",
        "\n",
        "# Optional: Visualize feature importance as a bar plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Importance', y='Feature', data=feature_importance_df)\n",
        "plt.title(\"Feature Importance based on LinearSVC Coefficients\")\n",
        "plt.xlabel(\"Importance\")\n",
        "plt.ylabel(\"Feature\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "33UNFshQrDU8",
        "outputId": "9d05cb69-c97a-41b3-fcb9-ca2dcc98cf51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "partially initialized module 'pandas' has no attribute '_pandas_parser_CAPI' (most likely due to a circular import)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-b9bd7588c2da>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Import necessary libraries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearSVC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    136\u001b[0m )\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplotting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtseries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_print_versions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/api/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"\"\" public toolkit API \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m from pandas.api import (\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mindexers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0minterchange\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/api/typing/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# TODO: Can't import Styler without importing jinja2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# from pandas.io.formats.style import Styler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_json\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mJsonReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStataReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/json/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from pandas.io.json._json import (\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mread_json\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mto_json\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mujson_dumps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mujson_loads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mparse_table_schema\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m )\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreaders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mTYPE_CHECKING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from pandas.io.parsers.readers import (\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mTextFileReader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mTextParser\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mread_csv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mread_fwf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_libs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_libs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSTR_NA_VALUES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m from pandas.errors import (\n\u001b[1;32m     34\u001b[0m     \u001b[0mAbstractMethodError\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36minit pandas._libs.parsers\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'pandas' has no attribute '_pandas_parser_CAPI' (most likely due to a circular import)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we apply SMOTE only to the training set to avoid a form of data leakage, which occurs when information from the test or validation sets influences the training process. Here’s why:\n",
        "\n",
        "* The goal of validation and test sets is to simulate how the model will perform on completely unseen data. If we apply SMOTE to the entire dataset, synthetic examples based on validation or test data will indirectly influence the model during training. This creates an \"unfair\" advantage, as the model has indirectly seen patterns from future (test/validation) data.\n",
        "\n",
        "* SMOTE creates synthetic samples by interpolating between points in the feature space. Applying it only to the training set ensures these synthetic samples are based solely on the training data distribution. This keeps the validation and test sets \"pure\" and independent, providing an unbiased evaluation of model performance.\n",
        "\n",
        "By using SMOTE exclusively on the training set, we maintain a realistic measure of model generalization to new data.\n",
        "\n",
        "NOTE: Synthetic samples in the context of SMOTE (Synthetic Minority Over-sampling Technique) are artificially generated data points created to balance class distributions in imbalanced datasets. Here’s how SMOTE generates them:\n",
        "\n",
        "SMOTE Generates Synthetic samples by:\n",
        "\n",
        "* Generating New Data Points: SMOTE creates synthetic samples for the minority class by selecting a data point from the minority class and generating new data points between it and its nearest neighbors from the same class.\n",
        "\n",
        "* Interpolating Between Points: SMOTE doesn’t just duplicate minority class examples; instead, it finds nearby points in the feature space (minority samples) and interpolates to create a new sample that is somewhere between the two original samples.\n",
        "\n"
      ],
      "metadata": {
        "id": "0ly9YhkyrsfZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results of balanced dataset\n"
      ],
      "metadata": {
        "id": "6Boyuiq2AtQy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validation Set"
      ],
      "metadata": {
        "id": "o0uQHYbiFz2P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy:**\n",
        "\n",
        "* The model achieves an accuracy of 0.80 (or 80%) on the validation set, indicating that 80% of predictions are correct. However, given the class imbalance (while SMOTE helps mitigate class imbalance during training, it doesn’t fully solve all issues with imbalanced performance. To further improve, we might consider additional strategies like adjusting decision thresholds, using cost-sensitive learning, or employing other classifiers that handle class imbalance effectively), accuracy alone might not reflect the model’s true performance on both classes.\n",
        "\n",
        "**Precision:**\n",
        "\n",
        "* Class 0 (No Delay): Precision is high at 0.84, meaning 84% of flights predicted as \"No Delay\" were correct.\n",
        "\n",
        "* Class 1 (Delay): Precision is lower at 0.39, so only 39% of flights predicted as \"Delay\" were actually delayed.\n",
        "\n",
        "**Recall:**\n",
        "\n",
        "* Class 0: High recall of 0.94, meaning 94% of actual \"No Delay\" flights were correctly identified.\n",
        "\n",
        "* Class 1: Low recall of 0.17, indicating that only 17% of actual \"Delay\" flights were correctly identified. This suggests the model often misses delays.\n",
        "\n",
        "**F1-Score:**\n",
        "\n",
        "* Class 0: High F1-score of 0.89, reflecting a good balance between precision and recall for \"No Delay.\"\n",
        "\n",
        "* Class 1: Low F1-score of 0.24 due to low recall, showing poor performance in identifying delays.\n",
        "\n",
        "**Macro and Weighted Averages:**\n",
        "\n",
        "* Macro Avg: Averages precision, recall, and F1-score equally across both classes, resulting in lower scores (0.56 for recall and F1) due to the poor recall for delays.\n",
        "\n",
        "* Weighted Avg: Reflects the class imbalance by giving more weight to Class 0, resulting in higher overall scores (0.80 accuracy and 0.77 weighted F1-score).\n",
        "\n",
        "**Confusion Matrix:**\n",
        "\n",
        "* The matrix highlights the model’s strong performance in identifying non-delayed flights but its struggle with delays, with many delays incorrectly classified as \"No Delay.\""
      ],
      "metadata": {
        "id": "Q2cvUv5tF3KI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Set"
      ],
      "metadata": {
        "id": "cz0WxUUsIEAY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy**:\n",
        "\n",
        "* The model achieves 0.74 (74%) accuracy on the test set, which is lower than the validation accuracy, suggesting a slight drop in performance on truly unseen data.\n",
        "\n",
        "**Precision:**\n",
        "\n",
        "* Class 0: High precision of 0.75, meaning 75% of \"No Delay\" predictions were correct.\n",
        "\n",
        "* Class 1: Precision is somewhat better at 0.66, indicating that 66% of \"Delay\" predictions were correct.\n",
        "\n",
        "**Recall:**\n",
        "\n",
        "* Class 0: Very high recall at 0.97, so almost all non-delayed flights were correctly identified.\n",
        "\n",
        "* Class 1: Low recall of 0.16, indicating that only 16% of actual delays were correctly identified. This means the model misses a large portion of delayed flights.\n",
        "\n",
        "**F1-Score:**\n",
        "\n",
        "* Class 0: F1-score of 0.84, reflecting a good balance between precision and recall for non-delayed flights.\n",
        "\n",
        "* Class 1: F1-score of 0.26 due to low recall, showing poor performance in identifying delays.\n",
        "\n",
        "**Macro and Weighted Averages:**\n",
        "\n",
        "* Macro Avg: Shows lower averages due to poor recall for delays (0.56 for recall and 0.55 for F1-score).\n",
        "\n",
        "* Weighted Avg: Skewed by the high number of non-delayed flights, with overall metrics of 0.74 for accuracy and 0.68 for the weighted F1-score.\n",
        "\n",
        "**Confusion Matrix:**\n",
        "\n",
        "Similar to the validation set, the confusion matrix for the test set indicates that the model effectively identifies non-delayed flights but struggles significantly with delayed flights.\n"
      ],
      "metadata": {
        "id": "sLk0dj3tIHGh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ROC Curve:** The ROC curve plots the True Positive Rate (Recall) against the False Positive Rate for different threshold values.\n",
        "\n",
        "* AUC (Area Under the Curve) = 0.70: This value indicates the model’s ability to distinguish between the two classes. An AUC of 0.70 suggests that the model has moderate discriminatory power, though it’s not particularly strong. A perfect model would have an AUC of 1.0, and a model with no discriminatory power would have an AUC of 0.5.\n",
        "\n",
        "* Curve Shape: The ROC curve initially rises but then flattens out as the False Positive Rate increases, which is common for models with moderate performance. The curve above the diagonal (gray dashed line) shows that the model performs better than random guessing, but there is room for improvement.\n",
        "\n",
        "* Interpretation: This ROC curve and AUC value indicate that the model is somewhat effective at separating delayed flights from non-delayed flights but could benefit from improvements, especially in recognizing the minority class (delayed flights).\n",
        "\n",
        "**Precision-Recall (PR) Curve:** The Precision-Recall curve plots Precision against Recall (True Positive Rate) for various threshold values.\n",
        "\n",
        "* Curve Shape: The curve starts with high precision at very low recall and then declines as recall increases. This decline shows that as the model captures more true positives (increasing recall), precision decreases, likely due to an increasing number of false positives.\n",
        "\n",
        "* Interpretation: Low Precision at Higher Recall: This curve indicates that when the model tries to capture more of the minority class (delays), precision drops, suggesting that the model struggles to maintain accuracy in identifying delays as it attempts to capture more of them. Imbalance Challenges: Precision-Recall curves are particularly useful for imbalanced datasets. Here, the curve suggests that the model has difficulty balancing precision and recall effectively for the minority class, indicating room for improvement in delay prediction.\n",
        "\n"
      ],
      "metadata": {
        "id": "XN7yqxsPKONI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overall Summary/Findings"
      ],
      "metadata": {
        "id": "FH0VIEWwIn3j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The model performs well for non-delayed flights (high recall and F1-score for class 0) but poorly for delayed flights, with low recall and F1-score for class 1.\n",
        "\n",
        "* The low recall for class 1 on both sets indicates that the model often misses delayed flights, which could be problematic if predicting delays is crucial.\n",
        "\n",
        "* The ROC curve and AUC indicate moderate overall performance in class discrimination.\n",
        "\n",
        "* The Precision-Recall curve highlights challenges in achieving a good balance between precision and recall for delays, especially given the class imbalance. Improvements could involve methods that focus on recall or alternative strategies like threshold adjustments.\n",
        "\n",
        "* Potential improvements include techniques like threshold tuning, using alternative classifiers, or additional sampling strategies to improve recall for the delayed class."
      ],
      "metadata": {
        "id": "lw3draekIqr-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Next Steps"
      ],
      "metadata": {
        "id": "AS9lvuVJI1Ur"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To improve the recall and F1-score for the minority class (delayed flights), we can try different oversampling techniques:\n",
        "\n",
        "While SMOTE is a popular technique, we might also consider:\n",
        "\n",
        "* ADASYN (Adaptive Synthetic Sampling): ADASYN is a variation of SMOTE that focuses on creating more synthetic samples for minority class points that are harder to classify.\n",
        "\n",
        "* Borderline-SMOTE: This variant of SMOTE generates synthetic points only near the decision boundary, potentially improving the model’s ability to differentiate between classes near the boundary.\n",
        "\n",
        "* Undersample the Majority Class: Sometimes a combination of oversampling the minority class and undersampling the majority class can improve model performance, as this reduces the imbalance while also minimizing the risk of overfitting to synthetic samples.\n",
        "\n",
        "We can also try ddjusting the Decision Threshold:\n",
        "\n",
        "* By default, many classifiers use a threshold of 0.5 for binary classification. We can adjust this threshold to increase the recall of the minority class by lowering the threshold for classifying a flight as \"Delayed.\"\n",
        "\n",
        "* We can experiment with different thresholds and evaluate the effect on precision, recall, and F1-score using the validation set. The ideal threshold will often depend on the specific trade-offs you want (e.g., a higher recall at the cost of precision).\n"
      ],
      "metadata": {
        "id": "5i8XQOL_JAU3"
      }
    }
  ]
}