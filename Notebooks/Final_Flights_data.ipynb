{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "kQBYdD_8TCN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_csv_from_zips(dataset_folder, output_folder, output_file):\n",
        "    \"\"\"\n",
        "    Merges CSV files from multiple ZIP archives into a single CSV file.\n",
        "\n",
        "    Parameters:\n",
        "    - dataset_folder: Path where ZIP files are stored.\n",
        "    - output_folder: Path where the merged CSV file will be saved.\n",
        "    - output_file: Name of the merged CSV file.\n",
        "    \"\"\"\n",
        "    # Create the output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # List to store DataFrames\n",
        "    df_list = []\n",
        "\n",
        "    # Iterate over all .zip files in the dataset folder\n",
        "    for filename in os.listdir(dataset_folder):\n",
        "        if filename.endswith('.zip'):\n",
        "            zip_path = os.path.join(dataset_folder, filename)\n",
        "            with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "                # Iterate through the files in the zip and check for CSVs\n",
        "                for file in zip_ref.namelist():\n",
        "                    if file.endswith('.csv'):\n",
        "                        # Read the CSV file directly from the zip file\n",
        "                        with zip_ref.open(file) as csv_file:\n",
        "                            df = pd.read_csv(csv_file)\n",
        "                            df_list.append(df)\n",
        "                        print(f\"CSV file {file} from {filename} added to the DataFrame list.\")\n",
        "                    else:\n",
        "                        print(f\"No CSV file found in {filename}\")\n",
        "\n",
        "    # Concatenate all DataFrames\n",
        "    if df_list:\n",
        "        merged_df = pd.concat(df_list, ignore_index=True)\n",
        "\n",
        "        # Check for successful merging\n",
        "        print(f\"Merged DataFrame shape: {merged_df.shape}\")\n",
        "\n",
        "        # Save the concatenated DataFrame to the output folder\n",
        "        output_path = os.path.join(output_folder, output_file)\n",
        "        merged_df.to_csv(output_path, index=False)\n",
        "\n",
        "        print(f\"All CSV files have been merged and saved to {output_path}\")\n",
        "        return merged_df  # Return the merged DataFrame for further use\n",
        "    else:\n",
        "        print(\"No CSV files were found to merge.\")\n",
        "        return None\n",
        "\n"
      ],
      "metadata": {
        "id": "qL8Gk2bFOjLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_flight_data(df):\n",
        "   # Create a weather delay indicator\n",
        "    delay_threshold = 15  # Minutes\n",
        "    df['WEATHER_DELAY_IND'] = df['DEP_DELAY'].apply(lambda x: 1 if x > delay_threshold else 0)\n",
        "\n",
        "    # Columns to drop\n",
        "    # columns_to_drop = [\n",
        "    #     'DEP_DELAY', 'DEP_DELAY_NEW',    # Actual departure times and delays\n",
        "    #     'ARR_TIME', 'ARR_DELAY', 'ARR_DELAY_NEW',    # Actual arrival times and delays\n",
        "    #     'ARR_TIME_BLK',                              # Arrival time block\n",
        "    #     'CANCELLED',            # Cancellation information\n",
        "    #     'AIR_TIME', 'FLIGHTS',                       # Actual flight duration and performance\n",
        "    #     'WEATHER_DELAY',                             # Actual weather delay (data leakage)\n",
        "    #     'TAIL_NUM',                                  # Aircraft tail number (high cardinality)\n",
        "    #     'ORIGIN_AIRPORT_ID', 'DEST_AIRPORT_ID',      # Redundant with ORIGIN and DEST\n",
        "    #     'ORIGIN_STATE_ABR', 'DEST_STATE_ABR',        # Redundant state abbreviations\n",
        "    #     'DEP_TIME_BLK'                               # Departure time block (high cardinality)\n",
        "    # ]\n",
        "\n",
        "\n",
        "    df =  df[df['ORIGIN_STATE_NM'].isin(['New York', 'Colorado', 'California', 'Florida', 'Texas', 'Illinois', 'Georgia', 'New Jersey', 'Maryland', 'Nevada'])]\n",
        "\n",
        "    df = df.drop_duplicates()\n",
        "\n",
        "    # Drop the columns from the DataFrame\n",
        "    # df.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "T3IRgiN_Wqbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nw9Lsw_4kLSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_hhmm_to_time(hhmm):\n",
        "    \"\"\"Converts HHMM format to time object.\"\"\"\n",
        "    if pd.isnull(hhmm) or hhmm == '':\n",
        "        return None\n",
        "    hhmm = int(hhmm)\n",
        "    hours = hhmm // 100\n",
        "    minutes = hhmm % 100\n",
        "    # Handle cases where hhmm is invalid\n",
        "    if hours >= 24 or minutes >= 60:\n",
        "        return None\n",
        "    return datetime.strptime(f'{hours:02d}:{minutes:02d}', '%H:%M').time()\n",
        "\n",
        "def get_departure_datetime(row):\n",
        "    # Extract FL_DATE\n",
        "    FL_DATE = row['FL_DATE']\n",
        "\n",
        "    flight_date = pd.to_datetime(FL_DATE).date()\n",
        "    # Extract CRS_DEP_TIME\n",
        "    DEP_TIME = row.get('CRS_DEP_TIME')\n",
        "\n",
        "    # Use scheduled time if actual time is missing\n",
        "    if pd.isnull(DEP_TIME) or DEP_TIME == '':\n",
        "        DEP_TIME = row.get('DEP_TIME')\n",
        "\n",
        "    # Convert time to datetime.time object\n",
        "    dep_time = convert_hhmm_to_time(DEP_TIME)\n",
        "\n",
        "    # Combine flight_date and dep_time to get departure_datetime\n",
        "    departure_datetime = datetime.combine(flight_date, dep_time)\n",
        "\n",
        "    return pd.Series({'departure_datetime': departure_datetime})\n",
        "\n",
        "def convert_time_to_minutes(time):\n",
        "    time_str = '{0:0>4}'.format(int(time))\n",
        "    hours = int(time_str[:2])\n",
        "    minutes = int(time_str[2:])\n",
        "\n",
        "    return hours * 60 + minutes\n",
        "\n",
        "\n",
        "def add_departure_datetime_column(df):\n",
        "\n",
        "    # Apply the function to each row in the DataFrame\n",
        "    df['departure_datetime'] = df.apply(lambda row: get_departure_datetime(row), axis=1)\n",
        "    df['departure_datetime'] = pd.to_datetime(df['departure_datetime'], format='%Y-%m-%d %H:%M:%S')\n",
        "    df['departure_resample15'] = df['departure_datetime'].dt.round('15min')\n",
        "\n",
        "    # Extract useful time features\n",
        "    df['CRS_DEP_HOUR'] = df['departure_datetime'].dt.hour\n",
        "    # df['CRS_DEP_MONTH'] = df['departure_datetime'].dt.month\n",
        "    # df['CRS_DEP_DAY_OF_WEEK'] = df['departure_datetime'].dt.dayofweek + 1  # Monday=0 in pandas\n",
        "\n",
        "\n",
        "    df['CRS_DEP_TIME_MINUTES'] = df['CRS_DEP_TIME'].apply(convert_time_to_minutes)\n",
        "    df = df.drop_duplicates()\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "ZjGsAah-SQEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to merge CSV files from ZIP archives and save them into a single CSV file.\n",
        "    \"\"\"\n",
        "    # Define the dataset folder containing the ZIP files\n",
        "    dataset_folder = '/content/Dataset'  # Change this path to your dataset folder\n",
        "\n",
        "    # Define the output folder and file name for the merged CSV\n",
        "    output_folder = 'output'             # Output folder where merged CSV will be stored\n",
        "    output_file = 'merged_Jan_2024.csv'  # Output CSV file name\n",
        "\n",
        "    # Step 1: Merge CSV files from ZIP archives\n",
        "    merged_df = merge_csv_from_zips(dataset_folder, output_folder, output_file)\n",
        "\n",
        "    # Step 2: If merging was successful, process the departure datetime column\n",
        "    merged_df = clean_flight_data(merged_df)  # Clean the data\n",
        "    merged_df = add_departure_datetime_column(merged_df)\n",
        "\n",
        "    # Step 3: Save the final DataFrame with the new departure_datetime column\n",
        "    final_output_file = 'merged_Jan_2024_with_departure_datetime.csv'\n",
        "    final_output_path = os.path.join(output_folder, final_output_file)\n",
        "    print('Shape of Final merged file : ', merged_df.shape)\n",
        "    merged_df.to_csv(final_output_path, index=False)\n",
        "\n",
        "    print(f\"Final CSV with departure datetime saved to {final_output_path}\")"
      ],
      "metadata": {
        "id": "XiLqw8xfOjOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if this script is being run directly and call main\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpSK_hXgOowW",
        "outputId": "3cbb2209-276f-424c-9846-4e607b6ff2f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file T_ONTIME_REPORTING.csv from DL_SelectFields (5).zip added to the DataFrame list.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-1c6306a875e7>:27: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(csv_file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file T_ONTIME_REPORTING.csv from DL_SelectFields.zip added to the DataFrame list.\n",
            "CSV file T_ONTIME_REPORTING.csv from DL_SelectFields (7).zip added to the DataFrame list.\n",
            "CSV file T_ONTIME_REPORTING.csv from DL_SelectFields (2).zip added to the DataFrame list.\n",
            "CSV file T_ONTIME_REPORTING.csv from DL_SelectFields (3).zip added to the DataFrame list.\n",
            "CSV file T_ONTIME_REPORTING.csv from DL_SelectFields (8).zip added to the DataFrame list.\n",
            "CSV file T_ONTIME_REPORTING.csv from DL_SelectFields (1).zip added to the DataFrame list.\n",
            "CSV file T_ONTIME_REPORTING.csv from DL_SelectFields (6).zip added to the DataFrame list.\n",
            "CSV file T_ONTIME_REPORTING.csv from DL_SelectFields (9).zip added to the DataFrame list.\n",
            "CSV file T_ONTIME_REPORTING.csv from DL_SelectFields (4).zip added to the DataFrame list.\n",
            "Merged DataFrame shape: (596071, 38)\n",
            "All CSV files have been merged and saved to output/merged_Jan_2024.csv\n",
            "Shape of Final merged file :  (317795, 43)\n",
            "Final CSV with departure datetime saved to output/merged_Jan_2024_with_departure_datetime.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SKwD_NwweaOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iJsen3Svuf0b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}